\pagebreak
\section{Nền tảng toán học và triển khai mô hình}
\subsection{Nền tảng toán học}
\subsubsection{Mô hình Softmax Regression}
Mô hình \textit{Softmax Regression} được sử dụng để giải quyết bài toán phân loại đa lớp (\textit{multi-class classification}) trên tập dữ liệu MNIST. Với một mẫu đầu vào được biểu diễn bởi vector đặc trưng $\displaystyle x \in \mathbb{R}^{d}$ (trong đó $d$ là số chiều của không gian đặc trưng), mô hình trước tiên tính toán điểm số tuyến tính (logits) tương ứng với $K$ lớp thông qua phép biến đổi sau:
\begin{center}
    $\displaystyle z = Wx+b$.
\end{center}
Trong đó:
\begin{itemize}
    \item $W \in \mathbb{R}^{K \times d}$ là ma trận trọng số;
    \item $b \in \mathbb{R}^{K}$ là vector bias;
    \item $z \in \mathbb{R}^{K}$ là vector điểm số.
\end{itemize}
Để chuyển các điểm số tuyến tính $z$ thành một phân phối xác suất hợp lệ trên không gian nhãn, mô hình sử dụng hàm kích hoạt \textit{softmax}. Xác suất để mẫu $x$ thuộc lớp $k$ được xác định bởi:
\begin{center}
    $\displaystyle \hat{y}_k = P(y = k | x) = softmax(z_k) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}$.
\end{center}
Trong đó, $z_k$ là điểm số ứng với lớp $k$, và mẫu số $\sum_{j=1}^{K} e^{z_j}$ đảm bảo rằng tổng các xác suất bằng 1, tạo thành một phân phối xác suất chuẩn hóa trên $K$ lớp.
\subsubsection{Hàm mất mát (Loss Function)}
Để huấn luyện mô hình, ta sử dụng hàm mất mát \textit{Cross-Entropy} nhằm đo lường mức độ khác biệt giữa phân phối xác suất dự đoán và nhãn thực tế. Đồng thời, nhằm hạn chế hiện tượng quá khớp (\textit{overfitting}), một thành phần điều chuẩn L2 (\textit{L2 Regularization}) được bổ sung vào hàm mất mát tổng quát. Cụ thể, hàm mất mát được định nghĩa như sau:
\begin{center}
    $\displaystyle J(W, b) = - \frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i,k} \log \hat{y}_{ik} + \frac{\lambda}{2} \sum_{l} \sum_{m} W_{lm}^2$.
\end{center}
Trong đó:
\begin{itemize}
    \item $N$ là số lượng mẫu trong một batch;
    \item $y_{i,k}$ là thành phần của vector one-hot label (bằng 1 nếu mẫu $i$ thuộc lớp $k$, ngược lại bằng 0);
    \item $\lambda$ (ký hiệu là \texttt{reg} trong mã nguồn) là hệ số điều chuẩn.
\end{itemize}
Trong biểu thức trên, hạng tử cross-entropy (hạng tử thứ nhất) thúc đẩy mô hình tối đa hóa xác suất dự đoán đúng, trong khi hạng tử điều chuẩn (hạng tử thứ hai) giúp giới hạn độ lớn của các trọng số, từ đó nâng cao khả năng tổng quát hóa của mô hình.
\subsubsection{Giải thuật tối ưu Gradient Descent}
Quá trình huấn luyện mô hình được thực hiện bằng thuật toán \textit{Mini-batch Gradient Descent}. Ở mỗi bước lặp, ta tính gradient của hàm mất mát đối với các tham số $W$ và $b$. Nhờ đặc tính giải tích thuận lợi của hàm softmax khi kết hợp với hàm mất mát cross-entropy, các biểu thức đạo hàm thu được có dạng đơn giản và hiệu quả như sau:
\begin{center}
    $\displaystyle \frac{\partial J}{\partial z} = \hat{y} - y$,
    $\displaystyle \frac{\partial J}{\partial W} = \frac{1}{N} X^T (\hat{y}-y) + \lambda W$,
    $\displaystyle \frac{\partial J}{\partial b} = \frac{1}{N} \sum (\hat{y}-y)$.
\end{center}
Trong đó $X \in \mathbb{R}^{N \times d}$ là ma trận dữ liệu đầu vào của mini-batch gồm $N$ mẫu.\\
Quy tắc cập nhật tham số với tốc độ học $\alpha$ (\textit{learning rate}) được thể hiện như sau:
\begin{center}
    $\displaystyle W \leftarrow W - \alpha \frac{\partial J}{\partial W}$,
    $\displaystyle b \leftarrow b - \alpha \frac{\partial J}{\partial b}$.
\end{center}
Nhờ việc sử dụng mini-batch, quá trình tối ưu vừa duy trì sự ổn định của gradient, vừa đảm bảo hiệu năng tính toán phù hợp cho các tập dữ liệu lớn.


\subsubsection{Quy trình huấn luyện mô hình}

\begin{algorithm}[H]
\caption{Hàm huấn luyện \texttt{fit}}
\begin{algorithmic}[1]
\Function{fit}{$X_{\text{train}}, y_{\text{train}}, X_{\text{val}}, y_{\text{val}}, \text{epochs}, \text{batch\_size}$}
    \State $N \gets \text{rows}(X_{\text{train}})$
    \State $\text{history.train\_loss} \gets [\,]$
    \State $\text{history.val\_acc} \gets [\,]$
    \For{$\text{epoch} \gets 1$ \textbf{to} $\text{epochs}$}
        \State $\text{indices} \gets \text{RandomPermutation}(\{0,\dots,N-1\})$
        \State $X_{\text{train}} \gets X_{\text{train}}[\text{indices}]$
        \State $y_{\text{train}} \gets y_{\text{train}}[\text{indices}]$
        \State $\text{epoch\_loss} \gets 0$
        \State $\text{n\_batches} \gets 0$
        \For{$\text{start} \gets 0$ \textbf{to} $N$ \textbf{step} $\text{batch\_size}$}
            \State $\text{end} \gets \text{start} + \text{batch\_size}$
            \State $X_{\text{batch}} \gets X_{\text{train}}[\text{start}:\text{end}]$
            \State $y_{\text{batch}} \gets y_{\text{train}}[\text{start}:\text{end}]$
            \State $(L, \nabla_W, \nabla_b) \gets \text{ComputeLossAndGrads}(X_{\text{batch}}, y_{\text{batch}})$
            \State $\text{epoch\_loss} \gets \text{epoch\_loss} + L$
            \State $\text{n\_batches} \gets \text{n\_batches} + 1$
            \State $W \gets W - \text{lr} \cdot \nabla_W$
            \State $b \gets b - \text{lr} \cdot \nabla_b$
        \EndFor
        \State $\text{avg\_loss} \gets \text{epoch\_loss} / \max(\text{n\_batches}, 1)$
        \State $\text{history.train\_loss.append}(\text{avg\_loss})$
        \If{$X_{\text{val}} \neq \varnothing$ \textbf{and} $y_{\text{val}} \neq \varnothing$}
            \State $\hat{y}_{\text{val}} \gets \text{Predict}(X_{\text{val}})$
            \State $\text{val\_acc} \gets \text{Mean}(\hat{y}_{\text{val}} = y_{\text{val}})$
            \State $\text{history.val\_acc.append}(\text{val\_acc})$
        \EndIf
    \EndFor
    \State \Return $\text{history}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{itemize}
    \item Xáo trộn (\emph{shuffle}) tập huấn luyện ở đầu mỗi epoch bằng một hoán vị ngẫu nhiên các chỉ số.
    \item Chia dữ liệu đã xáo trộn thành các mini-batch có kích thước \texttt{batch\_size}.
    \item Với mỗi mini-batch, gọi \texttt{ComputeLossAndGrads} để tính giá trị hàm mất mát và gradient theo $W$, $b$.
    \item Cập nhật tham số theo quy tắc gradient descent: $W \leftarrow W - \text{lr} \cdot \nabla_W$, $b \leftarrow b - \text{lr} \cdot \nabla_b$.
    \item Tính loss trung bình của toàn bộ các mini-batch trong một epoch và lưu vào \texttt{history.train\_loss}.
    \item Nếu có tập validation, tính độ chính xác trên $X_{\text{val}}$ và lưu vào \texttt{history.val\_acc}.
\end{itemize}

\subsubsection{Quy trình suy diễn và dự đoán}

\begin{algorithm}[H]
\caption{Hàm suy diễn \texttt{predict\_proba} và \texttt{predict}}
\begin{algorithmic}[1]
\Function{predict\_proba}{$X$}
    \State $Z \gets X W^\top + b$
    \State $Z' \gets Z - \max(Z \text{ theo từng hàng})$
    \State $\expZ \gets \exp(Z')$
    \State $P \gets \expZ / \sum(\expZ \text{ theo từng hàng})$
    \State \Return $P$
\EndFunction

\Function{predict}{$X$}
    \State $P \gets \text{predict\_proba}(X)$
    \State $\hat{y} \gets \arg\max(P \text{ theo từng hàng})$
    \State \Return $\hat{y}$
\EndFunction
\end{algorithmic}
\end{algorithm}


\begin{itemize}
    \item \texttt{predict\_proba}:
    \begin{itemize}
        \item Tính điểm số tuyến tính $Z = X W^\top + b$ cho tất cả mẫu và tất cả lớp.
        \item Chuẩn hoá $Z$ theo từng hàng để ổn định số học, sau đó áp dụng hàm softmax để thu được ma trận xác suất $P$.
    \end{itemize}
    \item \texttt{predict}:
    \begin{itemize}
        \item Gọi lại \texttt{predict\_proba} để lấy phân phối xác suất trên các lớp cho từng mẫu.
        \item Chọn lớp có xác suất lớn nhất bằng toán tử $\arg\max$ theo chiều lớp, thu được vector nhãn dự đoán $\hat{y}$.
    \end{itemize}
\end{itemize}

